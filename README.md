ğŸ  Underwater Species Detection & Classification
ğŸ“Œ Project Overview

This project presents an end-to-end deep learning pipeline for automated detection, tracking, and classification of underwater species from video data. The system is designed to identify fish and coral species in real-world underwater environments where challenges such as low visibility, motion blur, lighting variation, and occlusion are common.

The solution combines object detection, feature extraction, and video-level classification to produce annotated output videos with bounding boxes, class labels, confidence scores, and persistent object tracking.

ğŸ¯ Key Objectives

Detect underwater species accurately from raw video streams

Classify detected objects into species-level categories

Maintain object identity across frames using tracking

Generate an annotated output video for visual validation

Design a scalable pipeline that supports adding new species

ğŸ§  Methodology & Workflow
1ï¸âƒ£ Data Preparation

Collected underwater videos and image datasets

Extracted frames from videos and manually annotated species

Organized datasets into train / validation / test splits

Augmented data to handle class imbalance and underwater distortions

2ï¸âƒ£ Object Detection (YOLO)

Used YOLO (You Only Look Once) for real-time object detection

YOLO detects fish and coral regions in each video frame

Bounding boxes are generated for all detected objects

3ï¸âƒ£ Feature Extraction & Classification (EfficientNet)

Cropped detected regions are passed to EfficientNet

EfficientNet performs fine-grained species classification

Chosen for its compound scaling, high accuracy, and efficiency

Suitable for limited datasets and video-based inference

4ï¸âƒ£ Tracking & Video Processing

Integrated object tracking to assign unique IDs across frames

Ensures consistent labeling of the same species throughout the video

Implemented using OpenCV-based tracking techniques

5ï¸âƒ£ Output Generation

Generated annotated output videos containing:

Bounding boxes

Species names

Confidence scores

Object IDs

Saved outputs for qualitative evaluation and presentation

ğŸ› ï¸ Technologies Used

YOLO â€“ Object Detection

EfficientNet â€“ Feature Extraction & Classification

TensorFlow / Keras â€“ Model Training & Inference

OpenCV â€“ Video Processing & Tracking

Python â€“ Core Development

ğŸ“Š Evaluation & Validation

Evaluated model performance using:

Precision, Recall, F1-score

Confusion Matrix

Visual validation through annotated video outputs

ğŸš€ Key Highlights

Handles real-world underwater challenges effectively

Modular pipeline (easy to add new species)

Optimized for video-based inference

Combines detection, classification, and tracking in one system

ğŸ”® Future Enhancements

Expand to larger multi-species datasets

Improve tracking with DeepSORT

Deploy as a real-time monitoring system

Integrate with mobile or web-based dashboards


Developed as part of an advanced deep learning and computer vision project focused on marine ecosystem analysis.
